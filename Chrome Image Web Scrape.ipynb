{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e240b94-dec3-4755-8726-7eeec8a5080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime as dt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "from urllib.parse import quote_plus\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# Download the driver from the ChromeDriver website for the relevant OS i.e. MAC, Windows, Debian, etc.\n",
    "PATH = r'C:/path/to/your/chromedriver.exe'\n",
    "service = Service(executable_path=PATH)\n",
    "\n",
    "# Initialize the WebDriver with the Service object\n",
    "wd = webdriver.Chrome(service=service)\n",
    "\n",
    "def get_images_from_google(wd, delay, max_images, url):\n",
    "    def scroll_down(wd):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    wd.get(url)\n",
    "\n",
    "    image_urls = set()\n",
    "    skips = 0\n",
    "    while len(image_urls) + skips < max_images:\n",
    "        scroll_down(wd)\n",
    "        thumbnails = wd.find_elements(By.CLASS_NAME, \"mNsIhb\")\n",
    "\n",
    "        for img in thumbnails[len(image_urls) + skips:max_images]:\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(delay)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            images = wd.find_elements(By.CLASS_NAME, \"sFlh5c\")\n",
    "            for image in images:\n",
    "                if image.get_attribute('src') in image_urls:\n",
    "                    max_images += 1\n",
    "                    skips += 1\n",
    "                    break\n",
    "\n",
    "                if image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "                    image_urls.add(image.get_attribute('src'))\n",
    "                    ##print(f\"Found {len(image_urls)}\")\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "def download_image(down_path, url, file_name, image_type='JPEG', verbose=True):\n",
    "    try:\n",
    "        time = dt.now()\n",
    "        curr_time = time.strftime('%H:%M:%S')\n",
    "        # Content of the image will be a url\n",
    "        img_content = requests.get(url).content\n",
    "        # Get the bytes IO of the image\n",
    "        img_file = io.BytesIO(img_content)\n",
    "        # Stores the file in memory and convert to image file using Pillow\n",
    "        image = Image.open(img_file)\n",
    "        file_pth = down_path + file_name\n",
    "\n",
    "        with open(file_pth, 'wb') as file:\n",
    "            image.save(file, image_type)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'The image: {file_pth} downloaded successfully at {curr_time}.')\n",
    "    except Exception as e:\n",
    "        print(f'Unable to download image from Google Photos due to\\n: {str(e)}')\n",
    "\n",
    "def find_duplicates(directory_path):\n",
    "    command = [\n",
    "        'find-dups',\n",
    "        directory_path,\n",
    "        '--algorithm', 'phash',\n",
    "        '--on-equal', 'delete-first',\n",
    "        '--parallel', '4'\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Ask user for the list of foods they want to search, separated by commas\n",
    "    food_list = input(\"Enter the names of the foods you want to search for, separated by commas: \").split(',')\n",
    "    food_list = [food.strip() for food in food_list]  # Remove any leading/trailing whitespace\n",
    "\n",
    "    # Loop to ensure valid integer input for the maximum number of images to scrape\n",
    "    while True:\n",
    "        try:\n",
    "            max_images = int(input(\"Enter the maximum number of images to scrape for each food item: \"))\n",
    "            break  # Exit the loop if a valid integer is entered\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid integer for the number of images.\")\n",
    "\n",
    "    # Get the current date in the format YYYY-MM-DD\n",
    "    current_date = dt.now().strftime('%Y-%m-%d')\n",
    "    base_directory = f'C:/Users/YourUserName/Desktop/Food AI/images/Malaysian Dish/{current_date}/'\n",
    "\n",
    "    # Make the base directory for the current date if it doesn't exist\n",
    "    if not os.path.exists(base_directory):\n",
    "        print(f'Making base directory for the current date: {base_directory}')\n",
    "        os.makedirs(base_directory)\n",
    "\n",
    "    for food_name in food_list:\n",
    "        # URL encode the food name for the Google search URL\n",
    "        search_query = quote_plus(food_name)\n",
    "        google_url = f\"https://www.google.com/search?q={search_query}&tbm=isch\"\n",
    "\n",
    "        # Directory to save the images, named after the food\n",
    "        sanitized_name = re.sub(r'[\\\\/:*?\"<>|]', '', food_name)\n",
    "        save_directory = os.path.join(base_directory, sanitized_name)\n",
    "        \n",
    "        # Make the directory for the specific food if it doesn't exist\n",
    "        if not os.path.exists(save_directory):\n",
    "            print(f'Making directory for {food_name}: {save_directory}')\n",
    "            os.makedirs(save_directory)\n",
    "\n",
    "        # Scrape images from Google\n",
    "        urls = get_images_from_google(wd, delay=0.5, max_images=max_images, url=google_url)\n",
    "        \n",
    "        # Download the images\n",
    "        for i, url in enumerate(urls):\n",
    "            download_image(down_path=save_directory + '/', \n",
    "                           url=url, \n",
    "                           file_name=str(i+1) + '.jpg',\n",
    "                           verbose=True)\n",
    "\n",
    "        # Find and handle duplicates\n",
    "        find_duplicates(save_directory)\n",
    "\n",
    "    # Close the webdriver\n",
    "    wd.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d708f48-08a3-4b5f-9fd5-ab77abe3dd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate detection result:\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Goreng\\2.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Goreng\\24.jpg with Hamming distance: 2 and similarity: 80.0%\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Penyek\\25.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Penyek\\33.jpg with Hamming distance: 2 and similarity: 80.0%\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Penyek\\24.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Penyek\\46.jpg with Hamming distance: 2 and similarity: 80.0%\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Penyek\\39.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Penyek\\65.jpg with Hamming distance: 2 and similarity: 80.0%\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Ayam\\15.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Ayam\\4.jpg with Hamming distance: 2 and similarity: 80.0%\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Ayam Penyek\\47.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Ayam\\49.jpg with Hamming distance: 0 and similarity: 100.0%\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Ayam\\31.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Ayam\\62.jpg with Hamming distance: 2 and similarity: 80.0%\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Lemak\\12.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Lemak\\23.jpg with Hamming distance: 2 and similarity: 80.0%\n",
      "Duplicate found: C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Lemak\\58.jpg and C:\\Users\\Naluri - Akmal\\Desktop\\Food AI\\images\\Malaysian Dish\\2024-08-31\\Nasi Lemak\\61.jpg with Hamming distance: 2 and similarity: 80.0%\n",
      "Note: It is preferable to check if the image similarity is below 50% before deciding to delete.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# Find and delete duplicates based on the Hamming distance threshold\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mdelete_smallest_duplicates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhamming_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 58\u001b[0m, in \u001b[0;36mdelete_smallest_duplicates\u001b[1;34m(directory_path, hamming_threshold)\u001b[0m\n\u001b[0;32m     55\u001b[0m duplicates \u001b[38;5;241m=\u001b[39m find_duplicates(directory_path, hamming_threshold)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: It is preferable to check if the image similarity is below 50% before deciding to delete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDo you want to delete all the duplicate image:? (y/any key to skip) \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dup1, dup2 \u001b[38;5;129;01min\u001b[39;00m duplicates:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to delete all the duplicate image:? (y/any key to skip)  n\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import imagehash\n",
    "\n",
    "def find_duplicates(directory_path, hamming_threshold):\n",
    "    image_hashes = {}  # Dictionary to store image hashes\n",
    "    duplicates = []  # List to store pairs of duplicate images\n",
    "\n",
    "    # Calculate image hashes for each image in the directory\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "                image_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    image = Image.open(image_path)\n",
    "                    image_hash = imagehash.phash(image)\n",
    "                    \n",
    "                    # Check for duplicates using Hamming distance\n",
    "                    found_duplicate = False\n",
    "                    for existing_hash, existing_path in image_hashes.items():\n",
    "                        hamming_distance = image_hash - existing_hash\n",
    "                        if hamming_distance <= hamming_threshold:\n",
    "                            duplicates.append((existing_path, image_path))\n",
    "                            found_duplicate = True\n",
    "                            break\n",
    "                    \n",
    "                    # Only add to the dictionary if no duplicate was found\n",
    "                    if not found_duplicate:\n",
    "                        image_hashes[image_hash] = image_path\n",
    "\n",
    "                except UnidentifiedImageError:\n",
    "                        print(f\"Cannot identify image file: {image_path}. Deleting file.\")\n",
    "                        os.remove(image_path)  # Automatically delete the file\n",
    "\n",
    "\n",
    "    print(\"Duplicate detection result:\")\n",
    "    if duplicates:\n",
    "        for dup1, dup2 in duplicates:\n",
    "            # Calculate the Hamming distance\n",
    "            hash1 = imagehash.phash(Image.open(dup1))\n",
    "            hash2 = imagehash.phash(Image.open(dup2))\n",
    "            distance = hash1 - hash2\n",
    "            similarity = calculate_similarity(distance, hamming_threshold)\n",
    "            print(f\"Duplicate found: {dup1} and {dup2} with Hamming distance: {distance} and similarity: {similarity}%\")\n",
    "    else:\n",
    "        print(\"No duplicates found.\")\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "def calculate_similarity(hamming_distance, max_distance):\n",
    "    similarity_percentage = (1 - (hamming_distance / max_distance)) * 100\n",
    "    return round(similarity_percentage, 2)\n",
    "\n",
    "def delete_smallest_duplicates(directory_path, hamming_threshold):\n",
    "    duplicates = find_duplicates(directory_path, hamming_threshold)\n",
    "\n",
    "    print(f\"Note: It is preferable to check if the image similarity is below 50% before deciding to delete.\")\n",
    "    choice = input(f\"Do you want to delete all the duplicate image:? (y/any key to skip) \").strip().lower()\n",
    "\n",
    "    if choice == 'y' and choice == 'Y':\n",
    "        for dup1, dup2 in duplicates:\n",
    "            size1 = os.path.getsize(dup1)\n",
    "            size2 = os.path.getsize(dup2)\n",
    "            if size1 < size2:\n",
    "                print(f\"Deleting smaller file: {dup1}\")\n",
    "                os.remove(dup1)\n",
    "            else:\n",
    "                print(f\"Deleting smaller file: {dup2}\")\n",
    "                os.remove(dup2)\n",
    "\n",
    "    else:\n",
    "        print(\"Skipping deletion for all possible duplicate images.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    hamming_threshold = 10  # Define the maximum Hamming distance to consider images as duplicates\n",
    "    # Change your directory to the one where you want to find and delete duplicate images\n",
    "    directory_path = r'C:/Users/YourUserName/Desktop/Food AI/images/Malaysian Dish/'\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory {directory_path} does not exist.\")\n",
    "    else:\n",
    "        # Find and delete duplicates based on the Hamming distance threshold\n",
    "        delete_smallest_duplicates(directory_path, hamming_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e9760-2811-4716-8fcf-d7be15c4c62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChromeImageScrape",
   "language": "python",
   "name": "chromeimagescrape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
